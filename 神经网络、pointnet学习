1、多层感知机可类比为泰勒展开式
2、sklearn.datasets中的 make_classification方法，其中 random_state 参数为随机种子，可保证同一种子下数据相同
3、sklearn.pregrocessing 的 3 种常见用法（scaler.fit_transform(X)）：
  （1）StandardScaler：标准化，将数据变换为均值为 0，标准差为 1 的标准正态分布。
  （2）MinMaxScaler：归一化，将数据按比例缩放到 [0, 1] 范围内（或其他指定范围）。
  （3）RobustScaler：鲁棒缩放，通过中位数和四分位差进行缩放，鲁棒性强，适用于含有离群点的数据。
4、在很多框架中，包括 PyTorch，需要手动为每一层添加激活函数。网络本身并不自动插入激活函数，因此需要显式地在每一层后添加激活函数（例如 ReLU、Sigmoid 等），
   并通过 forward 方法定义它们的应用顺序。
5、神经网络的简单部署流程：
  （1）定义class的成员变量：
        a、调用父类初始化函数
        b、定义连接层 fc1、fc2
        c、定义激活函数
        d、定义输出层处理方式（比如分类任务用softmax将logits转为概率分布）
  （2）定义class的成员方法：
        a、forward 方法，其中定义了数据如何通过网络进行计算和传递，最终得到输出
  （3）初始化模型，包括：
        a、设置输入层、隐藏层、输出层大小
        b、model实例化
        c、选择损失函数
        d、选择和定义优化器（需要传入model的可调参数）
  （4）

